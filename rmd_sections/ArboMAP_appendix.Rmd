---
output: pdf_document
---
\newpage

# Appendix

This appendix will provide more details into some of the underlying forecast modeling and break out the results per model, rather than an average of all models run (as in the main report). 

## Forecast results

### Current-week WNV absolute risk

Following are the absolute risk maps generated by **each** model:

```{r appx_abs_risk_map, echo=FALSE, include=TRUE, fig.align='center', out.width="90%", results="asis"}

# Creates a map of absolute risk of the requested forecast week
# for each model

appx_preds_fc_wk <- preds %>% 
  dplyr::filter(year_epi == epiyear_request & week_epi == epiweek_request)


#loop for each model
for (i in seq_along(model_names)){
  
  #this model
  this_model <- model_names[i]
  this_model_desc <- model_desc_names[[this_model]]
  this_abs_risk <- appx_preds_fc_wk %>% 
    dplyr::filter(model == this_model)
  
  #title section
  this_model_title <- paste0(this_model_desc, ": \"", this_model, "\"")
  # #note needs results='asis' in code block header
  # cat("#### ", this_model_title)
  # [DMN] Removed b/c often not on same page, looked off
  
  #join with spatial
  this_sf_abs_risk <- data_sf %>% 
    dplyr::left_join(this_abs_risk, by = "arbo_ID")
  
  this_p_abs_risk <- ggplot2::ggplot() +
    ggplot2::geom_sf(data = this_sf_abs_risk,
                     aes(fill = pred,
                         #fake alpha to get NA legend entry
                         alpha = "Not able to model")) +
    viridis::scale_fill_viridis("", 
                                #limits always 0 - 1
                                limits = c(0, 1),
                                breaks = c(0, 1),
                                labels = c("0: Less likely\nto report any cases", 
                                           "1: More likely\nto report at least one case"),
                              na.value = color_risk_na) +
    #fake scale for NA legend entry
    scale_alpha_manual("", values = 1) +
    ggtitle("Absolute risk in forecast week",
            subtitle = this_model_title) +
    theme_arbo_map +
    #override legend for alpha to get correct
    guides(alpha = guide_legend("", override.aes = list(fill = color_risk_na),
                                #reorder legends for that color ramp is first
                                order = 2)) +
    guides(fill = guide_colorbar(order = 1))
  
  plot(this_p_abs_risk)
}

```

\newpage
### Current-week WNV relative risk

Following are the relative risk maps generated by **each** model:

```{r appx_rel_risk_map, echo=FALSE, include=TRUE, fig.align='center', out.width="90%", results='asis'}

# V4 algorithm
# For each model:
# 1. For each county-year, get the pred value at the same EPI WEEK as the forecast week
# 2. RANK these pred values and divide by the number of years of values each county has.
#     This creates a ~percentile of RANKED risk (basically)
# 3. Percentile values kept as continuous to match style of absolute risk maps
#     [V3]: <= 12.5% lower than ave, => 87.5% higher than ave
#     Will need to indicate something similar in legend
# 4. Map each model
# Note: This is therefore the relative risk of PREDICTED values. 
#     May want to consider if there is some way to compare forecast-week predicted value
#       against OBSERVED historical values (any_cases), but not certain how that 
#       mathematically would work out (as any_cases is {0|1}). [DMN]

#rank the specific week's pred against the other years
appx_rel_risk <- preds %>% 
  #get all preds at same epiweek (in any year)
  dplyr::filter(week_epi == epiweek_request) %>% 
  # rank within each county & model
  dplyr::group_by(arbo_ID,
                  model) %>% 
  dplyr::mutate(rank_pred = rank(pred, ties.method = 'random'),
                #percentile of ranked pred by number of years
                # note: rank such that lowest pred = 1
                rank_perc = rank_pred / n() * 100) %>% 
  #and get this current-year week
  dplyr::filter(year_epi == epiyear_request) %>% 
  #ungroup to finish
  dplyr::ungroup()

#same breaks as [V3]
lower_risk <- 12.5
higher_risk <- 87.5

#loop for each model
for (i in seq_along(model_names)){
  
  #this model
  this_model <- model_names[i]
  this_model_desc <- model_desc_names[[this_model]]
  this_rel_risk <- appx_rel_risk %>% 
    dplyr::filter(model == this_model)
  
  #title section
  this_model_title <- paste0(this_model_desc, ": \"", this_model, "\"")
  ##note needs results='asis' in code block header
  #cat("#### ", this_model_title)
  # [DMN] Removed because often not ending up on same page
  
  #this model's data joined with spatial
  this_sf_rel_risk <- data_sf %>% 
    dplyr::left_join(this_rel_risk,
                     by = "arbo_ID")
  
  #this model's plot
  this_p_rel_risk <- ggplot2::ggplot() +
    #by rank percentile
    ggplot2::geom_sf(data = this_sf_rel_risk,
                     aes(fill = rank_perc,
                       #fake alpha to get NA legend entry
                       alpha = "Not able to model")) +
    viridis::scale_fill_viridis("", 
                                #limits always 0 - 100
                                limits = c(0, 100),
                                #using [V3] breaks
                                breaks = c(0, lower_risk, 50, higher_risk, 100),
                                labels = c("0",
                                           paste(lower_risk, ": Lower than average risk"),
                                           "50: Average risk",
                                           paste(higher_risk, ": Higher than average risk"),
                                           "100"),
                                na.value = color_risk_na) +
    #fake scale for NA legend entry
    scale_alpha_manual("", values = 1) +
    ggtitle("Risk in forecast week relative to the same epiweek in previous years",
            subtitle = this_model_title) +
    theme_arbo_map +
    #override legend for alpha to get correct
    guides(alpha = guide_legend("", override.aes = list(fill = color_risk_na),
                                #reorder legends for that color ramp is first
                                order = 2)) +
    guides(fill = guide_colorbar(order = 1))
  
  plot(this_p_rel_risk)
  
  #this model's table 
  if (this_rel_risk %>% 
      dplyr::filter(rank_perc >= higher_risk) %>% 
      nrow() > 0) {
    #Table of counties with higher than average risk
    this_kable <- knitr::kable(
      this_rel_risk %>% 
        dplyr::filter(rank_perc >= higher_risk) %>% 
        #join with crosswalk to get pretty names
        dplyr::left_join(id_crosswalk, by = "arbo_ID") %>% 
        dplyr::select(NAME, rank_perc),
      col.names = c("County", "Relative risk percentile"),
      digits = 2,
      align = c("l", "c"),
      caption = "Counties with higher than average risk")
    
  #note to get kable in a for loop, you must 
  # print kable with cat extra line WITH results='asis' in header
  #https://github.com/yihui/knitr/issues/886
  print(this_kable)
  cat("\n")}
  
}

```

\newpage
### Current-year forecasts

The graph below shows the current year forecast, with lines for **each** model:

```{r appx_curyr_forecast, echo=FALSE, include=TRUE, fig.align='center', fig.width=6, fig.height=3}

#Creates an epicurve of the current forecast year PREDICTIONS
# EACH model, no ribbon (as compared to average version in main report)
# Adds the HISTORICAL human epicurve 

# [DEV] Note that human summary data is on a different scale
#   than forecast, and ggplot2 does NOT allow for 2 different x-axes
# Rescaled by using the average historical proportion positive
#   as opposed to the [V3] count of countys positive


## Statewide predictions
appx_preds_st <- preds %>% 
  #not grouping by arbo_ID here
  dplyr::group_by(model, 
                  #keeping all date-related fields, 
                  # need to at least group on date_epi (or year+week)
                  date_epi, week_epi, year_epi, doy) %>% 
  dplyr::summarise(pred_ave = mean(pred, na.rm = TRUE),
                   mean_any_cases = mean(any_cases, na.rm = TRUE),
                   tot_case_count = sum(case_count, na.rm = TRUE), 
                   .groups = 'drop') %>% 
  #split into two series : pre & post fc_week - for graphing with two different styles
  #intentionally having fc week be both pre and post, so lines appear connected
  dplyr::mutate(pred_pre = dplyr::if_else(year_epi < epiyear_request, #previous years
                                          pred_ave,
                                          NA_real_),
                #earlier in forecast yr, update 
                pred_pre = dplyr::if_else(week_epi <= epiweek_request & 
                                            year_epi == epiyear_request, 
                                          pred_ave,
                                          pred_pre),
                pred_post = dplyr::if_else(week_epi >= epiweek_request & 
                                             year_epi == epiyear_request,
                                           pred_ave,
                                           NA_real_)) %>% 
  #censored to modelled range (with buffer)
  dplyr::filter(week_epi >= (human_wk_min - 1) &
                  week_epi <= (human_wk_max + 1))

appx_preds_curyr <- appx_preds_st %>% 
  #only forecast year
  dplyr::filter(year_epi == epiyear_request)

#human data already set up in main report
# keeping separate to graph, since separate from model type
#data_human_st_prop 

#pivot predictions long for ggplot
appx_preds_curyr_long <- appx_preds_curyr %>% 
  dplyr::select(week_epi, model, pred_pre, pred_post) %>% 
  tidyr::pivot_longer(cols = c(pred_pre,
                               pred_post),
                      names_to = "series",
                      values_to = "stat_value") %>% 
  #change order in legend
  dplyr::mutate(series = factor(series, levels = c("pred_pre", "pred_post")))

#Current year forecast plot
appx_p_cur_yr <- ggplot2::ggplot() +
  #human line
  geom_line(data = data_human_st_prop %>% 
              #censored to modelled range (with buffer)
              dplyr::filter(week_epi >= (human_wk_min - 1) &
                              week_epi <= (human_wk_max + 1)),
            aes(x = week_epi,
                y = pp_mean,
                #alpha to trick into creating a legend
                #only works b/c using default, a black solid line
                alpha = "human"),
            color = "black",
            linetype = "solid") +
  #per model predictions
  geom_line(data = appx_preds_curyr_long,
            aes(x = week_epi,
                y = stat_value,
                linetype = series,
                color = model)) +
  #current week marker
  geom_vline(xintercept = epiweek_request, linetype = "dashed", color = "grey25") +
  #plot labels and adjustments
  #for model colors (limiting spectrum b/c dark red/purple looks like black)
  scale_color_viridis("Model", option = "turbo", discrete = TRUE, begin = 0.1, end = 0.9) +
  #for pre/post forecast week
  scale_linetype_manual("Time linetype indicator",
                        values = c("pred_pre" = "solid",
                                   "pred_post" = 22), #22 is tight dashed
                        labels = c("pred_pre" = "Model Backcast",
                                   "pred_post" = "Model Forecast")) +
  #for tricking into human legend
  scale_alpha_manual("", 
                     values = c("human" = 1),
                     labels = c("human" = "Historical\naverage proportion")) +
  ggtitle(paste("Statewide model predictions made on", 
                epiyear_request, "week", epiweek_request)) +
  #[V3] How y-axis labeled in v3, keeping same [DMN]
  ylab("Proportion of counties positive") + 
  xlab("Epiweek") + 
  #theme
  theme_arbo_chart +
  #compact legends to fit
  theme(legend.margin = margin(),
        legend.key.height = unit(0.15, "in"),
        legend.spacing = unit(0.15, "in")) +
  #change order of legends
  guides(
    color = guide_legend(order = 1),
    linetype = guide_legend(order = 2),
    alpha = guide_legend(order = 3))

plot(appx_p_cur_yr)

```

### Case estimations

The table below lists the estimated case counts per model. 

```{r appx_pos_to_cases, echo=FALSE, include=TRUE}

#Estimates number of cases from positive county-weeks
# Splits out previous yearly summaries to model
#   and predicts on current year

#Uses pred_yrs_fc_yr created in main report, just before summarizing across models

#create table to display
knitr::kable(pred_yrs_fc_yr %>%
               dplyr::select(year_epi, model,
                             tot_pred, tot_pred_cases),
             col.names = c("Year", "Model",
                           "Predicted positive county-weeks", "Estimated cases"),
             digits = c(1,0), 
             align = c("l", "l", "c", "c"),
             caption = "Estimated number of WNV cases")

#DEV <<>> Include graphs?

```

### Additional model fit statistics

The table below gives multiple model fit statistic per forecast model:

* AUC : Area Under ROC Curve, values range 0 - 1. 
* AIC : Akaike information criterion, relative fit statistic to other models
* Temporal MAE : Mean Average Error, mean of weeks (collapsed to state)
* Spatial MAE : Mean Average Error, mean of counties (collapsed all time)

```{r appx_model_fit, echo=FALSE, include=TRUE}

#Creates a table of expanded model fit statistics BY model
# data created in forecast_modeling code block of main report
knitr::kable(model_evals_extra %>% 
               dplyr::select(model, auc, aic, mae_temporal, mae_spatial),
             col.names = c("Model", "AUC", "AIC", "MAE Temporal", "MAE Spatial"),
             digits = c(0, 3, 0, 3, 3),
             align = c("l", rep("c", 4)),
             caption = "Fit statistcs by model")
```

### Partial effects

ArboMAP allows the user to write custom model formulas, and as such the plots below are the partial effects of all the smooth terms for each model. These show the component effect of the term. All components (not just smooths) added together would be the overall prediction. For a table of all formulas, see the section on "Models and formulas".

The number after the comma in the `s({item}, {number})` labels is the effective degrees of freedom (EDF). The EDF is a measurement of the complexity of the smooth term - a value of 1 is a straight line, higher values are more complex curves. 

An easy way to check on the significance of the smooth term is if you cannot draw a horizontal line through the 95% confidence interval (value +/- se, shown in the gray shaded ribbon in the relevant graphs). 

All models with smooths will have 1-D graphs. Seasonally-varying models will also have 2-D graphs (components with `doymat` in standard models), however a subset of y-values have been pulled out to plot as lines. 

```{r appx_dep_fxs, include=TRUE, echo=FALSE, fig.align='center', results='asis', fig.width=5.5, fig.height=3}

# [V3] note copied verbatim:
# "Because the user can write model formulas from scratch, we are not able to assume anything about the regression model. Therefore, plotting the model is difficult when you don't know what components the model has. In what follows, every 1-/2-D plot from the chosen models are shown. These will have names assigned by the gam function, which should be comprehensible if the user built the model."

#Estimated dependence functions
# aka component smooth functions
# I believe I can call these 'partial effects' [DMN]
# [DMN] useful refs: 
# https://noamross.github.io/gams-in-r-course/chapter2 
# https://stackoverflow.com/questions/67077306/plotting-output-of-gam-model

#creates plots for each model
# uses the model_plots creating during forecast regression:
# from ?plot.gam() "plots the component smooth functions that make [a fitted gam object] up, on the scale of the linear predictor"
# pulls the data table out to replot nicer

# DEV NOTES FOR POSSIBLE CHANGES [DMN]
#1. REML "The difference is likely due to you using different fitting algorithms. The default in gam() is (currently) method = "GCV.Cp" even through the recommended option is to use method = "REML""

#[DMN] Had thought this was true, but I don't think so anymore
#The y-axis scale has been shifted so the y-value is the predicted `any_cases` (positive county-week) assuming all other terms in that model were at their average value.

#loop for each model
for (i in seq_along(model_names)){
  
  #this model
  this_model <- model_names[i]
  this_model_desc <- model_desc_names[[this_model]]
  #model_plots created in loop in forecast regression
  this_plot <- model_plots[[this_model]]

  #title section
  this_model_title <- paste0(this_model_desc, ": \"", this_model, "\"")
  cat("#### ", this_model_title, "\n")
  # #cat headers, but only in latex, doesn't work for html
  # if (knitr::is_latex_output()) {
  #   #note needs results='asis' in code block header, and \n to render properly
  #   cat("#### ", this_model_title, "\n")
  # }

  #each plot object seems to contain multiple plot objects
  # for each smooth term
  for (j in seq_along(this_plot)){
    
    this_subplot <- this_plot[[j]]
    
    #plots can either be 1-D or 2-D 
    # The test used in [V3] was if $main was NULL, kept for [V4]
    # Seems that all fixed models are 1-D, and seasonally-varying is 2-D
    
    if (is.null(this_subplot$main)){
      #1-D
      
      #sub in actual variable names
      this_ylab <- this_subplot$ylab %>% 
      stringr::str_replace(pattern = "var1", 
                           replacement = params$predictor_var1) %>% 
      stringr::str_replace(pattern = "var2", 
                           replacement = params$predictor_var2)

      
      #pull data
      this_subdata <- tibble::tibble(x = this_subplot$x,
                                     y = this_subplot$fit,
                                     se = this_subplot$se)
      
      #replot
      p_this_subplot <- ggplot2::ggplot() +
        #[V3]
        geom_hline(yintercept = 0, linetype = "longdash") +
        #partial effect
        geom_line(data = this_subdata,
                  aes(x = x, y = y)) +
        #se ribbon; added by [DMN] for [V4]
        geom_ribbon(data = this_subdata,
                    aes(x = x,
                        ymin = y - se, ymax = y + se),
                    alpha = 0.3) +
        xlab(this_subplot$xlab) +
        ylab("fit") +
        ggtitle(paste0("Component: ", this_ylab),
                subtitle = this_model) +
        theme_arbo_chart +
        #extra margin to prevent x-axis labels from being cut off
        #trbl : top right bottom left ('margins are trouble')
        theme(plot.margin = margin(10, 20, 10, 10)) 
      
    }#end 1-D
    
    if (!is.null(this_subplot$main)){
      #2-D
      
      #sub in actual variable names (from MAIN)
      this_component <- this_subplot$main %>% 
        stringr::str_replace(pattern = "var1", 
                           replacement = params$predictor_var1) %>% 
        stringr::str_replace(pattern = "var2", 
                           replacement = params$predictor_var2)

      
      #pull data
      this_subdata <- tidyr::expand_grid(x = this_subplot$x,
                                         y = this_subplot$y)
      this_subdata$fit <- this_subplot$fit
      
      #select a subset of y to plot as lines [V3]
      y_chosen <- quantile(this_subplot$y, probs = c(0.3, 0.5, 0.7), type = 3)
      this_subdata <- this_subdata %>% 
        dplyr::filter(y %in% y_chosen) %>% 
        dplyr::mutate(doy = factor(round_any(y, 1)))
      
      #[V3]
      p_this_subplot <- ggplot2::ggplot() +
        geom_hline(yintercept = 0, linetype = "longdash") +
        geom_line(data = this_subdata,
                  aes(x = x, y = fit,
                      group = doy, color = doy, linetype = doy)) +
        #https://colorbrewer2.org/#type=qualitative&scheme=Dark2&n=3
        scale_color_manual("Day of year\nsubset", values = c("#1b9e77", "#d95f02","#7570b3")) +
        scale_linetype_manual("Day of year\nsubset", values = c("solid", "dashed", "dotdash")) +
        xlab(this_subplot$xlab) +
        ylab("fit") +
        ggtitle(paste0("Component: ", this_component),
                subtitle = this_model) +
        theme_arbo_chart

    }#end 2-D
    
    plot(p_this_subplot)
    
    #neccessary for markdown to render properly inside loop
    cat("\n\n")
    
  }#end subplot loop
  
}#end model loop
```

\blandscape
### Multi-year forecasts

The graph below shows the full forecast for all years, with lines for **each** model:

```{r appx_multiyr_forecast, echo=FALSE, include=TRUE, fig.align='center', fig.width=10}

#Creates a multi-year time series chart of the predicted per model vs. 
#   observed positive county-weeks


appx_multiyr <- appx_preds_st %>% #from appx cur yr code block
  #update mean_any_cases to be NA during forecast year
  dplyr::mutate(mean_any_cases = dplyr::if_else(year_epi == epiyear_request,
                                                NA_real_,
                                                mean_any_cases)) %>% 
  #modified date to deal with skipping weeks between seasons
  # borrowed from [V3]
  # year + decimal fraction [DMN]
  dplyr::mutate(modwk = (week_epi - human_wk_min) / (human_wk_max - human_wk_min + 1),
                moddate = year_epi + modwk)

#for model forecasts
appx_multiyr_long <- appx_multiyr %>% 
  #pull needed and pivot long
  dplyr::select(model, moddate, 
                pred_pre, pred_post) %>% 
  tidyr::pivot_longer(cols = c(pred_pre, pred_post),
                      names_to = "series",
                      values_to = "value")

#for human data, using mean of any cases: appx_multiyr$mean_any_cases
#   i.e. NOT the same as current year graphs, which use ave by week of year of all years

appx_p_multiyr <- ggplot() +
  #historical any cases (observed)
  geom_line(data = appx_multiyr,
            aes(x = moddate,
                y = mean_any_cases,
                #alpha to trick into creating a legend
                #only works b/c using default, a black solid line
                alpha = "human"),
            color = "black",
            linetype = "solid") +
  #per model predictions
  geom_line(data = appx_multiyr_long,
            aes(x = moddate,
                y = value,
                linetype = series,
                color = model)) +
  #plot labels and adjustments
  #for model colors (limiting spectrum b/c dark red/purple looks like black)
  scale_color_viridis("Model", option = "turbo", discrete = TRUE, begin = 0.1, end = 0.9) +
  #for pre/post forecast week
  scale_linetype_manual("Time linetype indicator",
                        values = c("pred_pre" = "solid",
                                   "pred_post" = 22), #22 is tight dashed
                        labels = c("pred_pre" = "Past model forecast",
                                   "pred_post" = "Future model forecast")) +
  #for tricking into human legend
  scale_alpha_manual("", 
                     values = c("human" = 1),
                     labels = c("human" = "Historical observed")) +
  #x-axis management to only show the modeled weeks per year 
  #   borrowed heavily from [V3]
  scale_x_continuous(breaks = seq(from = params$year_human_start + 0.5,
                                  to = (params$year_human_end + 1.5),
                                  by = 1),
                     labels = seq(from = params$year_human_start, 
                                  to = params$year_human_end + 1, 
                                  by = 1),
                     limits = c((params$year_human_start),
                                (params$year_human_end + 2))) +
  ggtitle(paste("Statewide model predictions")) + 
  #change order of legends
  guides(
    color = guide_legend(order = 1),
    linetype = guide_legend(order = 2),
    alpha = guide_legend(order = 3)) +
  #[V3] How y-axis labeled in v3, keeping same [DMN]
  ylab("Proportion of counties positive") + 
  theme_arbo_chart +
  theme(legend.position="bottom", 
        #legend gets cut off so multiple rows across various aesthetics
        legend.box = "vertical", 
        legend.direction = "horizontal", 
        #compact
        legend.margin = margin(),
        legend.key.height = unit(0.15, 'in'))


plot(appx_p_multiyr)

```

\newpage
### Models and formulas

The table below lists the models that were found in the `r params$file_models` file. Standard models will have a text description, but all models run should appear in the table along with their formula. 

The following fields may be present: 

* `any_cases` : positive county-week
* `arbo_ID` : internal field for identifying counties
* `mir_stat` : the mosquito infection rate statistic
* `s(lag, by=var...)` : fixed smooth term for the environmental variable over the distributed lag period
* `te(lag, doymat, by=var...)` : seasonally-varying smooth term for the environmental variable over the distributed lag period
* `var1` : variable for `r params$predictor_var1`, observed value
* `var2` : variable for `r params$predictor_var2`, observed value
* `var1_anom` : variable for `r params$predictor_var1`, anomalized value
* `var2_anom` : variable for `r params$predictor_var2`, anomalized value
* `s(doy,...)` : smooth term for day of year, for seasonality

```{r appx_model_desc, echo=FALSE, include=TRUE, results='asis'}

#get named list info on models and combine into a single tibble
appx_full_mods <- model_formulas %>% 
  tibble::enframe(name = "model", value = "formula") %>% 
  dplyr::left_join(model_desc_names %>% 
                     tibble::enframe(name = "model", value = "desc"),
                   by = "model") %>% 
  dplyr::select(model, desc, formula)

#model display short name, descriptive name, & math formula
knitr::kable(appx_full_mods,
               col.names = c("Model", "Description", "Formula"))

```
\elandscape

## Data summaries

### Anomalized environmental variables

The report parameters set the two environmental predictor variables as `r params$predictor_var1` and `r params$predictor_var2`. The following two graphs show the median state-wide anomalized weather variables for the forecast year, compared to the historical median. 
Anomalies are calculated using deviance between the observed value and the predicted value from a GAM regression model using county and a smooth on day of year (seasonality) and county. An anomaly is the observed minus the predicted. 

Two or more consecutive days that have anomalized values **greater** than the anomalized historical median are drawn in `r colorize("red", "red")` and consecutive days that are **less** than the historical median are drawn in `r colorize("blue", "blue")`. Consecutive days that overlap the historical median (i.e. one day above and the next below, or the opposite) are in purple. The gray shaded region is a ribbon showing the historical range (min to max). 

```{r appx_anom_weather, echo=FALSE, include=TRUE, fig.align='center', fig.height=c(4,4), fig.width=c(7,7)}

#Create environmental data plots for the current year 
#   with historical doy information in background
# [V3] used medians, so retained in [V4]

#Note on tidyverse dynamic names
# We have to tell it to evaluate the variable that is the name of the variable
  #  by using !!sym() (or {{}} if it worked), 
  #  and if that's on the LHS, use := instead of =

# historical data - state-wide 
#   as opposed to by county data_env_hx
appx_data_env_doy <- data_env %>% 
  #summarize to state
  dplyr::group_by(doy) %>% 
  dplyr::summarise(            
    #medians
    !!rlang::sym(paste0(var1_anom_name, 
                        "_med")) := quantile(!!rlang::sym(var1_anom_name),
                                             probs = 0.5, na.rm = TRUE),
    !!rlang::sym(paste0(var2_anom_name,
                        "_med")) := quantile(!!rlang::sym(var2_anom_name),
                                             probs = 0.5, na.rm = TRUE),
    #mins
    !!rlang::sym(paste0(var1_anom_name, 
                        "_min")) := min(!!rlang::sym(var1_anom_name),
                                        na.rm = TRUE),
    !!rlang::sym(paste0(var2_anom_name,
                        "_min")) := min(!!rlang::sym(var2_anom_name),
                                        na.rm = TRUE),
    #maxs
    !!rlang::sym(paste0(var1_anom_name, 
                        "_max")) := max(!!rlang::sym(var1_anom_name),
                                        na.rm = TRUE),
    !!rlang::sym(paste0(var2_anom_name,
                        "_max")) := max(!!rlang::sym(var2_anom_name),
                                        na.rm = TRUE))

# this year data - state-wide
appx_data_env_fc_yr <- data_env %>% 
  dplyr::filter(year_epi == epiyear_request) %>% 
  #summarize to state using medians
  dplyr::group_by(doy) %>% 
  dplyr::summarise(            
    !!rlang::sym(paste0(var1_anom_name, 
                        "_med_yr")) := quantile(!!rlang::sym(var1_anom_name),
                                                probs = 0.5, na.rm = TRUE),
    !!rlang::sym(paste0(var2_anom_name,
                        "_med_yr")) := quantile(!!rlang::sym(var2_anom_name),
                                                probs = 0.5, na.rm = TRUE))

if (dev_write_output){
  #note folder modification since in rmd_sections subfolder
  readr::write_csv(appx_data_env_doy, file = file.path("..", out_folder, paste0(out_name_base, "_appx_data_env_appx_doy.csv")))
  readr::write_csv(appx_data_env_fc_yr, file = file.path("..", out_folder, paste0(out_name_base, "_appx_data_env_fc_appx_yr.csv")))
}

#segment line for showing color above/below median
#pasted median names for ease
var1_anom_med_name <- paste0(var1_anom_name, "_med")
var2_anom_med_name <- paste0(var2_anom_name, "_med")


# only plot IF there is data for the forecast year
#  there SHOULD be, but the if will prevent the report from throwing error
#  and failing to finish b/c of these graphs

if (nrow(appx_data_env_fc_yr) > 0){
  appx_data_env_colors <- appx_data_env_fc_yr %>% 
    dplyr::left_join(appx_data_env_doy %>% 
                       dplyr::select(doy, ends_with("_med")),
                     by = "doy") %>% 
    #line segments are drawn x to xend, y to yend
    # going to do day by day: x segments are doy to doy+1
    #   y segments are value + lead(1) value
    dplyr::mutate(var_x = doy, 
                  var_xend = dplyr::lead(var_x, n = 1),
                  var1_y = !!rlang::sym(paste0(var1_anom_med_name, "_yr")),
                  var1_yend = dplyr::lead(var1_y, n = 1),
                  var2_y =  !!rlang::sym(paste0(var2_anom_med_name, "_yr")),
                  var2_yend = dplyr::lead(var2_y, n = 1)) %>% 
    #now flag if y - yend is above, below, or crosses historical median
    dplyr::mutate(
      #var1
      color_var1 = case_when(
        var1_y >= !!rlang::sym(var1_anom_med_name) & 
          var1_yend >= !!rlang::sym(var1_anom_med_name) ~ "Higher",
        var1_y >= !!rlang::sym(var1_anom_med_name) & 
          var1_yend <= !!rlang::sym(var1_anom_med_name) ~ "Crosses",
        var1_y <= !!rlang::sym(var1_anom_med_name) & 
          var1_yend >= !!rlang::sym(var1_anom_med_name) ~ "Crosses",
        var1_y <= !!rlang::sym(var1_anom_med_name) & 
          var1_yend <= !!rlang::sym(var1_anom_med_name) ~ "Lower",
        TRUE ~ "forgotsomething"),
      #var2
      color_var2 = case_when(
        var2_y >= !!rlang::sym(var2_anom_med_name) & 
          var2_yend >= !!rlang::sym(var2_anom_med_name) ~ "Higher",
        var2_y >= !!rlang::sym(var2_anom_med_name) & 
          var2_yend <= !!rlang::sym(var2_anom_med_name) ~ "Crosses",
        var2_y <= !!rlang::sym(var2_anom_med_name) & 
          var2_yend >= !!rlang::sym(var2_anom_med_name) ~ "Crosses",
        var2_y <= !!rlang::sym(var2_anom_med_name) & 
          var2_yend <= !!rlang::sym(var2_anom_med_name) ~ "Lower",
        TRUE ~ "forgotsomething")) %>% 
    #lead(1) does not exist for last day in environmental data, so removing improper last entry
    dplyr::filter(!doy == max(data_env_fc_yr))
  
  #plot
  appx_p_env_var1_color <- ggplot() + 
    # min/max ribbon using wide data
    geom_ribbon(data = appx_data_env_doy, 
                aes(x = doy, 
                    ymin = !!rlang::sym(paste0(var1_anom_name, "_min")), 
                    ymax = !!rlang::sym(paste0(var1_anom_name, "_max")),
                    fill = "minmax")) +
    #historical median series
    geom_line(data = appx_data_env_colors,
              aes(x = doy, 
                  y = !!rlang::sym(var1_anom_med_name),
                  color = "Historical median")) +
    #line segment for year median with different colors
    geom_segment(data = appx_data_env_colors,
                 aes(x = var_x, xend = var_xend,
                     y = var1_y, yend = var1_yend,
                     color = color_var1),
                 size = 0.9) +
    #vertical line at the doy of requested date #linetype inside of aes to trigger legend
    geom_vline(aes(xintercept = doy_dt_epiwk_req, linetype = "forecast_doy"), color = "grey50") +
    #scales
    scale_fill_manual("",
                      values = c("minmax" = "grey80"),
                      labels = "Range over all years") +
    scale_linetype_manual("",
                          values = c("forecast_doy" = "dashed"),
                          labels = paste0("Day of year of requested\nforecast date: ", doy_dt_epiwk_req)) +
    scale_color_manual("Forecast year median\ncompared to historical median", 
                       values = env_comp_colors) +
    xlab("Day of the year") + 
    ylab(params$predictor_var1) +
    ggtitle(paste("Environmental data for anomalized", params$predictor_var1, 
                  "in", max(data_env$year_epi, na.rm=TRUE))) +
    theme_arbo_chart +
    theme(legend.position="bottom", 
          #legend gets cut off so multiple rows across various aesthetics
          legend.box="horizontal", 
          legend.direction = "vertical",
          #compact
          legend.margin = margin(),
          legend.key.height = unit(0.15, 'in')) +
    #changing order of legend
    guides(
      color = guide_legend(order = 1),
      linetype = guide_legend(order = 3),
      fill = guide_legend(order = 2))
  
  #plot
  appx_p_env_var2_color <- ggplot() + 
    # min/max ribbon using wide data
    geom_ribbon(data = appx_data_env_doy, 
                aes(x = doy, 
                    ymin = !!rlang::sym(paste0(var2_anom_name, "_min")), 
                    ymax = !!rlang::sym(paste0(var2_anom_name, "_max")),
                    fill = "minmax")) +
    #historical median series
    geom_line(data = appx_data_env_colors,
              aes(x = doy, 
                  y = !!rlang::sym(var2_anom_med_name),
                  color = "Historical median")) +
    #line segment for year median with different colors
    geom_segment(data = appx_data_env_colors,
                 aes(x = var_x, xend = var_xend,
                     y = var2_y, yend = var2_yend,
                     color = color_var2),
                 size = 0.9) +
    #vertical line at the doy of requested date #linetype inside of aes to trigger legend
    geom_vline(aes(xintercept = doy_dt_epiwk_req, linetype = "forecast_doy"), color = "grey50") +
    #scales
    scale_fill_manual("",
                      values = c("minmax" = "grey80"),
                      labels = "Range over all years") +
    scale_linetype_manual("",
                          values = c("forecast_doy" = "dashed"),
                          labels = paste0("Day of year of requested\nforecast date: ", doy_dt_epiwk_req)) +
    scale_color_manual("Forecast year median\ncompared to historical median", 
                       values = env_comp_colors) +
    xlab("Day of the year") + 
    ylab(params$predictor_var2) +
    ggtitle(paste("Environmental data for anomalized", params$predictor_var2, 
                  "in", max(data_env$year_epi, na.rm=TRUE))) +
    theme_arbo_chart +
    theme(legend.position="bottom", 
          #legend gets cut off so multiple rows across various aesthetics
          legend.box="horizontal", 
          legend.direction = "vertical",
          #compact
          legend.margin = margin(),
          legend.key.height = unit(0.15, 'in')) +
    #changing order of legend
    guides(
      color = guide_legend(order = 1),
      linetype = guide_legend(order = 3),
      fill = guide_legend(order = 2))
  
  plot(appx_p_env_var1_color)
  plot(appx_p_env_var2_color)
  
} #end if data for fc year

```

### Modeled mosquito infection rate

In modeling years where sufficient mosquito data were present, the mosquito infection rate (MIR) statistic was created using the model specified in the input parameter: `r mosquito_model_clean`. The following table presents the calculated centered MIR values that were used in the forecast modeling. 

```{r appx_mir, echo=FALSE, include=TRUE}

#kable of MIR summary stat from mosquito model
# pre imputation
# (imputed is always 0)

#pre imputation (mir_stat_ctr, by year, and potentially by strata)

if (mosquito_model_clean %in% mosq_nonstrat_models){
  knitr::kable(mosq_mir %>% 
                 dplyr::select(year_epi, mir_stat_ctr) %>% 
                 dplyr::arrange(year_epi),
               col.names = c("Year", "Centered MIR stat"),
               digits = 3,
               align = "c",
               caption = "Mosquito model summary statistic")
} else if (mosquito_model_clean %in% mosq_strat_models){
  knitr::kable(mosq_mir %>% 
                 dplyr::select(year_epi, strata, mir_stat_ctr) %>% 
                 dplyr::arrange(year_epi, strata),
               col.names = c("Year", "Stratum", "Centered MIR stat"),
               digits = 3,
               align = "c",
               caption = "Mosquito model summary statistic")
}
```




